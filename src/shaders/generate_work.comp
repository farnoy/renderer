#version 450

#extension GL_KHR_shader_subgroup_basic: require
#extension GL_KHR_shader_subgroup_ballot: require
#extension GL_KHR_shader_subgroup_shuffle: require
#extension GL_EXT_scalar_block_layout: require
#extension GL_KHR_shader_subgroup_vote : require

struct VkDrawIndexedIndirectCommand {
    uint indexCount;
    uint instanceCount;
    uint firstIndex;
    int vertexOffset;
    uint firstInstance;
};

layout(push_constant, scalar) uniform PushConstants {
    uint gltfIndex;
    uint indexCount;
    uint indexOffset;
    uint indexOffsetInOutput;
    int vertexOffset;
};

layout(set = 0, binding = 0, scalar) uniform ModelMatrices {
    mat4 model[4096];
};

layout(set = 1, binding = 0, scalar) uniform CameraMatrices {
    mat4 projection;
    mat4 view;
    vec4 position;
    mat4 pv;
};

layout(set = 2, binding = 0, scalar) buffer IndirectCommands {
    VkDrawIndexedIndirectCommand indirect_commands[2400];
};

layout(set = 2, binding = 1, scalar) buffer OutIndexBuffer {
    uvec3 out_index_buffer[20000000];
};

layout(set = 2, binding = 2, scalar) buffer readonly VertexBuffer {
    vec3 vertex_buffer[300000];
};

layout(set = 2, binding = 3, scalar) buffer readonly IndexBuffer {
    uvec3 index_buffer[300000];
};

#ifdef RGA
// RGA generates a scalar wavefront without it
layout (local_size_x = 512) in;
#endif
layout (local_size_x_id = 1) in;

shared uint globalOffset;

void main() {
    if (gl_GlobalInvocationID.x == 0) {
        // indexCount is preinitialized to 0 before a barrier, here would be too late
        indirect_commands[gltfIndex].instanceCount = 1;
        indirect_commands[gltfIndex].firstInstance = gltfIndex;
        indirect_commands[gltfIndex].firstIndex = indexOffsetInOutput;
        indirect_commands[gltfIndex].vertexOffset = vertexOffset;
    }
    if (gl_LocalInvocationID.x == 0) {
        globalOffset = 0;
    }
    barrier();

    bool cull = false;

    uvec3 ix;
    vec3[3] input_vertex;

    if (gl_GlobalInvocationID.x < indexCount / 3)
        ix = index_buffer[indexOffset / 3 + gl_GlobalInvocationID.x];

    // subgroup magic to exploit 3-tuple locality of indices
    const uint subgroup_vertices = 3; // how many vertices to load with subgroups
    const uint cluster_size = 4; // next power of two of subgroup_vertices
    // visual example for the algorithm, loading 3 elements from each invocation on gl_SubgroupSize=8
    // base=0
    // load:
    // 0           1        2        3        4        5         6        7
    // ix[0][0] ix[0][1] ix[0][2]   off    ix[4][0] ix[4][1] ix[4][2]    off
    // shuffle:
    // 0           1        2        3        4        5         6        7
    // 0,1,2      off      off      off     4,5,6     off       off      off 

    // base=1
    // load:
    // 0           1        2        3        4        5         6        7
    // ix[1][0] ix[1][1] ix[1][2]   off    ix[5][0] ix[5][1] ix[5][2]    off
    // shuffle:
    // 0           1        2        3        4        5         6        7
    // off       0,1,2     off      off      off     4,5,6      off      off
    // ...
    // base=3
    // load:
    // 0           1        2        3        4        5         6        7
    // ix[3][0] ix[3][1] ix[3][2]   off    ix[7][0] ix[7][1] ix[7][2]    off
    // shuffle:
    // 0           1        2        3        4        5         6        7
    // off        off      off     0,1,2     off      off       off     4,5,6
    for (uint base = 0; subgroup_vertices > 0 && base < cluster_size; base++) {
        uint load_lane;
        vec3 vertex;

        // shuffle addresses, invocations 0 .. subgroup_vertices will load the vertices of the first invocation
        // second cluster will start at the next power of two
        for (uint cluster_ix = 0; cluster_ix < subgroup_vertices; cluster_ix++) {
            uint shuffled_ix = subgroupShuffleXor(ix[cluster_ix], base ^ cluster_ix);
            if (gl_SubgroupInvocationID % cluster_size == cluster_ix)
                load_lane = shuffled_ix;
        }

        // this should be predicated to save bandwidth? but not predicating makes AMDVLK pull loads
        // as early as possible and hide latency that way
        // if (gl_SubgroupInvocationID % cluster_size < subgroup_vertices)
        vertex = vertex_buffer[vertexOffset + load_lane];

        for (uint vertex_offset = 0; vertex_offset < subgroup_vertices; vertex_offset++) {
            vec3 shuffled_load = subgroupShuffleXor(vertex, base ^ vertex_offset);
            if (gl_SubgroupInvocationID % cluster_size == base)
                input_vertex[vertex_offset] = shuffled_load;
        }
    }

    if (gl_GlobalInvocationID.x < indexCount / 3) {
        // load those vertices that were not loaded with the subgroup method
        for (uint vertex_offset = subgroup_vertices; vertex_offset < 3; vertex_offset++)
            input_vertex[vertex_offset] = vertex_buffer[vertexOffset + ix[vertex_offset]];

        mat4 model_mat = model[gltfIndex];
        vec4 vertex0 = pv * (model_mat * vec4(input_vertex[0], 1.0));
        vec4 vertex1 = pv * (model_mat * vec4(input_vertex[1], 1.0));
        vec4 vertex2 = pv * (model_mat * vec4(input_vertex[2], 1.0));

        // backface culling in counter clockwise front-facing order, left handed projection
        cull = determinant(mat3(vertex0.xyw, vertex1.xyw, vertex2.xyw)) > 0;

        vec3 ndc0 = vertex0.xyz / vertex0.w;
        vec3 ndc1 = vertex1.xyz / vertex1.w;
        vec3 ndc2 = vertex2.xyz / vertex2.w;

        if (!cull)
            cull =
                // frustum culling
                (ndc0.x < -1.0 && ndc1.x < -1.0 && ndc2.x < -1.0) ||
                (ndc0.x > 1.0 && ndc1.x > 1.0 && ndc2.x > 1.0) ||
                (ndc0.y < -1.0 && ndc1.y < -1.0 && ndc2.y < -1.0) ||
                (ndc0.y > 1.0 && ndc1.y > 1.0 && ndc2.y > 1.0);

        // degenerate triangle culling, this is a bad algorithm but even while being
        // conservative here, it discards a lot of stuff
        if (!cull) {
            float a = distance(ndc0, ndc1);
            float b = distance(ndc0, ndc2);
            float c = distance(ndc1, ndc2);
            float s = (a + b + c) / 2.0;
            float area = sqrt(s * (s - a) * (s - b) * (s - c));
            cull = area < 0.0000005; // magic constant
            cull = false; // disable for now
        }

        // live reloading playground - reject triangles after a certain number of them per mesh
        // cull = cull || (gl_GlobalInvocationID.x > 10000);

        uvec4 ballot = subgroupBallot(!cull);
        uint count = subgroupBallotBitCount(ballot);
        uint exclusiveBitCount = subgroupBallotExclusiveBitCount(ballot);

        uint offset = 0;
        if (subgroupElect()) {
            offset = atomicAdd(globalOffset, count);
        }
        offset = subgroupBroadcastFirst(offset);

        barrier();

        if (gl_LocalInvocationID.x == 0) {
            uint ix = atomicAdd(indirect_commands[gltfIndex].indexCount, globalOffset * 3);
            ix += indexOffsetInOutput; // to resume where previous mesh ended
            ix /= 3;
            globalOffset = ix;
        }

        barrier();

        if (!cull) {
            // repeating this load frees up register space needed in the previous section
            ix = index_buffer[indexOffset / 3 + gl_GlobalInvocationID.x];

            uint local_offset = globalOffset + offset + exclusiveBitCount;
            out_index_buffer[local_offset] = ix;
        }
    }
}
